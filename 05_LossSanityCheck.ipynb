{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2bfaedd",
   "metadata": {},
   "source": [
    "# Loss Sanity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0333711",
   "metadata": {},
   "source": [
    "In the previous notebook, we changed the forward pass so:\n",
    "\n",
    "1. We initialized our Jax network with the Keras weights (no improvement).\n",
    "2. We corrected the shapes of our network outputs (training loss now decreases).\n",
    "\n",
    "However we're still not done. The validation loss and MAE get worse and worse as our model trains. (We don't even have an initial period in which they do better...).\n",
    "\n",
    "In this notebook I want to:\n",
    "\n",
    "1. Make sure test loss and test MAE are calculated correctly (compare to Keras if possible).\n",
    "2. Make JAX training loss as close as possible to Keras training loss.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29907954",
   "metadata": {},
   "source": [
    "### Initialize Jax Network with Keras Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5360d24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import functools\n",
    "import optax\n",
    "\n",
    "from flax.core import frozen_dict\n",
    "from flax import struct\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d16c6ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv(\"data/movie-lens/rating.csv\", usecols=['userId', 'movieId', 'rating', 'y'])\n",
    "movies_df = pd.read_csv(\"data/movie-lens/movie.csv\", usecols=['movieId', 'title', 'year'])\n",
    "df = ratings_df.merge(movies_df, on='movieId').sort_values(by='userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac063ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138,493 distinct users rated 26,744 different movies (total ratings = 20,000,263)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle\n",
    "df = df.sample(frac=1, random_state=1) \n",
    "# First 50,000 for test\n",
    "test_df = df.iloc[:50000]\n",
    "# Rest for train\n",
    "train_df = df.iloc[50000:]\n",
    "\n",
    "n_movies = len(df.movieId.unique())\n",
    "n_users = len(df.userId.unique())\n",
    "print(\n",
    "    \"{1:,} distinct users rated {0:,} different movies (total ratings = {2:,})\".format(\n",
    "        n_movies, n_users, len(df),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46785325",
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class MovieLensConfig:\n",
    "  \"\"\"Global hyperparameters for our MovieLens Model\"\"\"\n",
    "  users_size: int = n_users + 1   # 138,494 (+1 because we are 1-indexed)\n",
    "  movies_size: int = n_movies + 0 # 26,744  (+0 because we are 0-indexed)\n",
    "  emb_dim: int = 8\n",
    "  dense_size_0: int = 32\n",
    "  dense_size_1: int = 4\n",
    "  out_size: int = 1\n",
    "  num_epochs: int = 10\n",
    "  batch_size: int = 5000\n",
    "  lr: float = 0.01\n",
    "  momentum: float = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7df74efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensModel(nn.Module):\n",
    "  \"\"\"A simple embedding model.\"\"\"\n",
    "\n",
    "  config: MovieLensConfig\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, user_id, movie_id):\n",
    "    \n",
    "    cfg = self.config\n",
    "    \n",
    "    user_id = user_id.astype('int32')\n",
    "    user_emb = nn.Embed(num_embeddings=cfg.users_size, embedding_init=nn.initializers.xavier_uniform(), features=cfg.emb_dim, name='user')(user_id)\n",
    "    \n",
    "    movie_id = movie_id.astype('int32')\n",
    "    movie_emb = nn.Embed(num_embeddings=cfg.movies_size, embedding_init=nn.initializers.xavier_uniform(), features=cfg.emb_dim, name='movie')(movie_id)\n",
    "    \n",
    "    x = jnp.concatenate((user_emb, movie_emb), axis=-1)\n",
    "    x = jnp.squeeze(x)\n",
    "        \n",
    "    x = nn.Dense(cfg.dense_size_0, kernel_init=nn.initializers.kaiming_uniform())(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.Dense(cfg.dense_size_1, kernel_init=nn.initializers.kaiming_uniform())(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.Dense(cfg.out_size, kernel_init=nn.initializers.kaiming_uniform())(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb3ae7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(rng, config):\n",
    "  \"\"\"Creates initial `TrainState`.\"\"\"\n",
    "  model = MovieLensModel(config)\n",
    "  user_id_fake = jnp.zeros((5,1), jnp.int32)\n",
    "  movie_id_fake = jnp.zeros((5,1), jnp.int32)\n",
    "  # Pass fake values through our model to initialize the parameters\n",
    "  params = model.init(rng, user_id_fake, movie_id_fake)['params']\n",
    "  \n",
    "  # TODO(joshvarty): Consider other optimizers.\n",
    "  #tx = optax.sgd(config.lr)\n",
    "  tx = optax.adam(0.005)\n",
    "  return train_state.TrainState.create(\n",
    "      apply_fn=model.apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d217d4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success.\n"
     ]
    }
   ],
   "source": [
    "# Check if we can create trainstate\n",
    "config = MovieLensConfig()\n",
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "state = create_train_state(init_rng, config)\n",
    "print(\"Success.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "480980a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "________________________________________________________________________________________\n",
      " Layer (type)                Output Shape       Param #   Connected to                  \n",
      "========================================================================================\n",
      " user_id (InputLayer)        [(None, 1)]        0         []                            \n",
      "                                                                                        \n",
      " movie_id (InputLayer)       [(None, 1)]        0         []                            \n",
      "                                                                                        \n",
      " user_embedding (Embedding)  (None, 1, 8)       1107952   ['user_id[0][0]']             \n",
      "                                                                                        \n",
      " movie_embedding (Embedding)  (None, 1, 8)      213952    ['movie_id[0][0]']            \n",
      "                                                                                        \n",
      " concatenate_2 (Concatenate)  (None, 1, 16)     0         ['user_embedding[0][0]',      \n",
      "                                                           'movie_embedding[0][0]']     \n",
      "                                                                                        \n",
      " flatten_2 (Flatten)         (None, 16)         0         ['concatenate_2[0][0]']       \n",
      "                                                                                        \n",
      " dense_4 (Dense)             (None, 32)         544       ['flatten_2[0][0]']           \n",
      "                                                                                        \n",
      " dense_5 (Dense)             (None, 4)          132       ['dense_4[0][0]']             \n",
      "                                                                                        \n",
      " prediction (Dense)          (None, 1)          5         ['dense_5[0][0]']             \n",
      "                                                                                        \n",
      "========================================================================================\n",
      "Total params: 1,322,585\n",
      "Trainable params: 1,322,585\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_keras_model(): \n",
    "  tf.random.set_seed(1)\n",
    "  np.random.seed(1)\n",
    "  random.seed(1)\n",
    "\n",
    "  hidden_units = (32,4)\n",
    "  movie_embedding_size = 8\n",
    "  user_embedding_size = 8\n",
    "\n",
    "  # Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "  user_id_input = keras.Input(shape=(1,), name='user_id')\n",
    "  movie_id_input = keras.Input(shape=(1,), name='movie_id')\n",
    "  user_embedded = keras.layers.Embedding(df.userId.max()+1, user_embedding_size, \n",
    "                                         input_length=1, name='user_embedding')(user_id_input)\n",
    "  movie_embedded = keras.layers.Embedding(df.movieId.max()+1, movie_embedding_size, \n",
    "                                          input_length=1, name='movie_embedding')(movie_id_input)\n",
    "  # Concatenate the embeddings (and remove the useless extra dimension)\n",
    "  concatenated = keras.layers.Concatenate()([user_embedded, movie_embedded])\n",
    "  out = keras.layers.Flatten()(concatenated)\n",
    "\n",
    "  # Add one or more hidden layers\n",
    "  for n_hidden in hidden_units:\n",
    "      out = keras.layers.Dense(n_hidden, activation='relu')(out)\n",
    "\n",
    "  # A single output: our predicted rating\n",
    "  out = keras.layers.Dense(1, activation='linear', name='prediction')(out)\n",
    "\n",
    "  model = keras.Model(\n",
    "      inputs = [user_id_input, movie_id_input],\n",
    "      outputs = out,\n",
    "  )\n",
    "  return model\n",
    "\n",
    "model = get_keras_model()\n",
    "keras_weights = model.get_weights()\n",
    "model.summary(line_length=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "126b60d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze params so we can update it directly.\n",
    "unfrozen_state_params = state.params.unfreeze()\n",
    "# Update with Keras weights\n",
    "unfrozen_state_params['user']['embedding'] = state.params['user']['embedding'].at[:].set(keras_weights[0])\n",
    "unfrozen_state_params['movie']['embedding'] = state.params['movie']['embedding'].at[:].set(keras_weights[1])\n",
    "unfrozen_state_params['Dense_0']['kernel'] = state.params['Dense_0']['kernel'].at[:].set(keras_weights[2])\n",
    "unfrozen_state_params['Dense_0']['bias'] = state.params['Dense_0']['bias'].at[:].set(keras_weights[3])\n",
    "unfrozen_state_params['Dense_1']['kernel'] = state.params['Dense_1']['kernel'].at[:].set(keras_weights[4])\n",
    "unfrozen_state_params['Dense_1']['bias'] = state.params['Dense_1']['bias'].at[:].set(keras_weights[5])\n",
    "unfrozen_state_params['Dense_2']['kernel'] = state.params['Dense_2']['kernel'].at[:].set(keras_weights[6])\n",
    "unfrozen_state_params['Dense_2']['bias'] = state.params['Dense_2']['bias'].at[:].set(keras_weights[7])\n",
    "# Freeze new params\n",
    "new_params = frozen_dict.freeze(unfrozen_state_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1acb546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update state\n",
    "new_state = state.replace(step=0, params=new_params, opt_state=state.opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "64c2bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the first few training examples\n",
    "train_df.iloc[0:5]\n",
    "user_id = train_df['userId'].iloc[0:5].values\n",
    "movie_id = train_df['movieId'].iloc[0:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0d447f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[ 0.00625672],\n",
       "             [ 0.00206297],\n",
       "             [-0.01768314],\n",
       "             [-0.04741435],\n",
       "             [-0.02822906]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One Step of Jax Forward Pass\n",
    "MovieLensModel(config).apply({'params': new_state.params}, user_id, movie_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "79877ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00625672],\n",
       "       [ 0.00206297],\n",
       "       [-0.01768313],\n",
       "       [-0.04741435],\n",
       "       [-0.02822906]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One step of Keras Forward Pass\n",
    "model.predict([user_id, movie_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3078bd3b",
   "metadata": {},
   "source": [
    "### Train JAX with new initial weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b344e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.partial(jax.jit, static_argnums=(0))\n",
    "def apply_model(cfg, state, user_id, movie_id, rating):\n",
    "  \n",
    "  def loss_fn(params):\n",
    "    logits = MovieLensModel(cfg).apply({'params': params}, user_id, movie_id)\n",
    "    #loss = jnp.mean(optax.l2_loss(predictions=logits, targets=rating))\n",
    "    loss = jnp.mean(jnp.square(logits - rating))\n",
    "    return loss, logits\n",
    "  \n",
    "  grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "  (loss, logits), grads = grad_fn(state.params)\n",
    "  mae = jnp.mean(jnp.abs(logits - rating))\n",
    "  return grads, loss, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "18f6e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def update_model(state, grads):\n",
    "  return state.apply_gradients(grads=grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8210c2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(cfg, state, train_df, rng):\n",
    "  \"\"\"Train for a single epoch.\"\"\"\n",
    "  train_df_size = len(train_df)\n",
    "  steps_per_epoch = train_df_size // cfg.batch_size\n",
    "  \n",
    "  perms = jax.random.permutation(rng, train_df_size)\n",
    "  perms = perms[:steps_per_epoch * cfg.batch_size]  # skip incomplete batch\n",
    "  perms = perms.reshape((steps_per_epoch, cfg.batch_size))\n",
    "  \n",
    "  epoch_loss = []\n",
    "  epoch_mae = []  \n",
    "\n",
    "  for perm in perms:\n",
    "    # x\n",
    "    batch_user_id = np.expand_dims(train_df.iloc[perm]['userId'].values, 1)\n",
    "    batch_movie_id = np.expand_dims(train_df.iloc[perm]['movieId'].values, 1)\n",
    "    # y\n",
    "    batch_rating = np.expand_dims(train_df.iloc[perm]['y'].values, 1)\n",
    "    \n",
    "\n",
    "    grads, loss, mae = apply_model(cfg, state, batch_user_id, batch_movie_id, batch_rating)\n",
    "    state = update_model(state, grads)\n",
    "    \n",
    "    user_emb_new = state.params['user']['embedding']\n",
    "    movie_emb_new = state.params['movie']['embedding']\n",
    "    \n",
    "    epoch_loss.append(loss)\n",
    "    epoch_mae.append(mae)\n",
    "    \n",
    "  train_loss = np.mean(epoch_loss)\n",
    "  train_mae = np.mean(epoch_mae)\n",
    "  return state, train_loss, train_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c454f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(config, train_df, test_df):\n",
    "  rng = jax.random.PRNGKey(0)\n",
    "  rng, init_rng = jax.random.split(rng)\n",
    "  # NOTE: This is where we're using the new Keras weights.\n",
    "  state = new_state\n",
    "  \n",
    "  for epoch in range(1, config.num_epochs + 1):\n",
    "    rng, input_rng = jax.random.split(rng)\n",
    "    state, train_loss, train_mae = train_epoch(config, state, train_df, rng)\n",
    "    \n",
    "    user_id = np.expand_dims(test_df['userId'].values, 1)\n",
    "    movie_id = np.expand_dims(test_df['movieId'].values, 1)\n",
    "    rating = np.expand_dims(test_df['y'].values, 1)\n",
    "    _, test_loss, test_mae = apply_model(config, state, user_id, movie_id, rating)\n",
    "    \n",
    "    print(\n",
    "        'epoch:% 3d, train_loss: %.4f, train_mae: %.4f, test_loss: %.4f, test_mae: %.4f'\n",
    "        % (epoch, train_loss, train_mae, test_loss, test_mae))\n",
    "    \n",
    "  return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c25c6b7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1, train_loss: 0.7204, train_mae: 0.6510, test_loss: 0.6883, test_mae: 0.6345\n",
      "epoch:  2, train_loss: 0.6619, train_mae: 0.6228, test_loss: 0.6665, test_mae: 0.6245\n",
      "epoch:  3, train_loss: 0.6351, train_mae: 0.6096, test_loss: 0.6537, test_mae: 0.6172\n",
      "epoch:  4, train_loss: 0.6194, train_mae: 0.6017, test_loss: 0.6465, test_mae: 0.6147\n",
      "epoch:  5, train_loss: 0.6091, train_mae: 0.5965, test_loss: 0.6447, test_mae: 0.6129\n",
      "epoch:  6, train_loss: 0.6014, train_mae: 0.5926, test_loss: 0.6427, test_mae: 0.6134\n",
      "epoch:  7, train_loss: 0.5954, train_mae: 0.5895, test_loss: 0.6424, test_mae: 0.6116\n",
      "epoch:  8, train_loss: 0.5907, train_mae: 0.5872, test_loss: 0.6405, test_mae: 0.6111\n",
      "epoch:  9, train_loss: 0.5868, train_mae: 0.5851, test_loss: 0.6406, test_mae: 0.6115\n",
      "epoch: 10, train_loss: 0.5836, train_mae: 0.5835, test_loss: 0.6384, test_mae: 0.6096\n"
     ]
    }
   ],
   "source": [
    "# Train Jax model with Keras weights.\n",
    "config = MovieLensConfig()\n",
    "state = train_and_evaluate(config, train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00557604",
   "metadata": {},
   "source": [
    "After correcting the inputs to be 2-dimensional instead of 1-Dimensions (eg. `[5,1]` vs `[5,]`) the training loss and test loss both seem to decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8b754a",
   "metadata": {},
   "source": [
    "It works! We get a better test MAE than the Keras tutorial (likely because we use a larger train set and smaller test set).\n",
    "\n",
    "Things I had to fix:\n",
    "\n",
    "1. Make sure to shuffle dataset so test is filled exclusively with users we've never seen before.\n",
    "\n",
    "2. Make sure that the train **and** test inputs are of the expected shape. Double check the loss values.\n",
    "\n",
    "3. Adam seems to work much better than SGD."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
